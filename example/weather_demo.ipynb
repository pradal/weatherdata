{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from agroservices import IPM\n",
    "from weatherdata.settings import pathCache\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfea\n",
    "\n",
    "\n",
    "class WeatherDataHub:    \n",
    "    \"\"\"\n",
    "        Allows to access at IPM weather resources \n",
    "        give the list of weather adapter (resources) available on IPM and allows access to weather data source\n",
    "        \n",
    "        ..doctest::\n",
    "        >>> wsh = WeatherDataHub()\n",
    "        >>> wsh.list_resources()\n",
    "        >>> wsh.get_resource(name = 'Finnish Meteorological Institute measured data')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Give an access to IPM interface from agroservice\n",
    "        \"\"\"\n",
    "        self.ipm = IPM()\n",
    "        self.sources = None\n",
    "    \n",
    "    @property\n",
    "    def __resources__(self):\n",
    "        \n",
    "        if self.sources is None:\n",
    "            self.sources= self.ipm.get_weatherdatasource()\n",
    "        \n",
    "        return {item[\"name\"]:item for item in self.sources}\n",
    "    \n",
    "    @property\n",
    "    def list_resources(self):\n",
    "        \"\"\" display a dataframe of list of resources with their description \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            name and description of available weatherdatasource on IPM service\n",
    "        \"\"\"   \n",
    "        df= pandas.DataFrame(self.__resources__).T.reset_index()\n",
    "        df.rename({\"index\":\"name\"},inplace=True)\n",
    "        \n",
    "        return df[[\"name\",\"description\",\"parameters\"]]\n",
    "                     \n",
    "    \n",
    "    def __forecast__(self):\n",
    "        return {key:bool(value[\"temporal\"][\"forecast\"])for key,value in ws.__resources__.items()}\n",
    "    \n",
    "    def __endpoint__(self):\n",
    "        return {key: value[\"endpoint\"] for key, value in ws.__resources__.items()}\n",
    "    \n",
    "        \n",
    "    def get_ressource(self, name: str):\n",
    "        \"\"\" Get ressource from WeatherDataSource\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "             name of weatherdatasource (available in list ressource)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        WeatherDataSource\n",
    "           weatherdatasource with the name of resource\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        NotImplementedError\n",
    "            the resource is unknown or the name of the resource is misspelled\n",
    "        \"\"\"        \n",
    "        keys = [item for item in self.__resources__]\n",
    "\n",
    "        if name in keys:\n",
    "            return WeatherDataSource(name,forecast=self.__forecast__()[name],endpoint=self.__endpoint__()[name])\n",
    "        else:\n",
    "            raise NotImplementedError(\"the resource is unknown or the name of the resource is misspelled\")\n",
    "\n",
    "class WeatherDataSource(WeatherDataHub):\n",
    "    def __init__(self, name, forecast,endpoint):\n",
    "        self.name = name\n",
    "        self.forecast=forecast\n",
    "        self.endpoint=endpoint\n",
    "        self.sources=None\n",
    "        self.ipm = IPM()\n",
    "    \n",
    "    @property\n",
    "    def __source__(self):\n",
    "        \n",
    "        if self.sources is None:\n",
    "            self.sources=self.__resources__\n",
    "            \n",
    "        source= self.sources[self.name]\n",
    "        return source\n",
    "          \n",
    "    \n",
    "    @property               \n",
    "    def parameter(self):\n",
    "        parameter= self.__source__[\"parameters\"]\n",
    "        return parameter\n",
    "    \n",
    "    @property\n",
    "    def stations(self):\n",
    "        if self.__source__[\"spatial\"][\"geoJSON\"] is not None:\n",
    "            features=json.loads(self.__source__[\"spatial\"][\"geoJSON\"])['features']\n",
    "            \n",
    "            #recupère les infos stations dans une properties\n",
    "            stations=[feature[\"properties\"] for feature in features]\n",
    "            \n",
    "            #recuperation et transformation des coordonnées\n",
    "            coord_tmp=[feature['geometry']['coordinates'] for feature in features]\n",
    "            station_coords= [{\"latitude\":float(coord[0]), \"longitude\":float(coord[1])} for coord in coord_tmp]\n",
    "            \n",
    "            # ajoute les coordonnées dans stations\n",
    "            for el in range(len(stations)):\n",
    "                stations[el].update(station_coords[el])\n",
    "            \n",
    "            # affichage des stations comme dataframe    \n",
    "            df= pandas.DataFrame(stations)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"No stations informations for this ressources\")\n",
    "        \n",
    "    def data(self,\n",
    "             parameters =[1002,3002], \n",
    "             stationId =[101104], \n",
    "             timeStart = '2020-06-12',\n",
    "             timeEnd = '2020-07-03',\n",
    "             timeZone = \"UTC\",\n",
    "             altitude = [70.0],\n",
    "             longitude = [14.3711],\n",
    "             latitude = [67.2828],\n",
    "             credentials = None,\n",
    "             interval = 3600,\n",
    "             display ='ds',\n",
    "             varname = 'id',\n",
    "             usecache =False,\n",
    "            savecache =False):\n",
    "        \n",
    "        responses=[] \n",
    "        \n",
    "        if self.forecast== False: \n",
    "            times= pandas.date_range(timeStart,timeEnd,freq='H',tz=timeZone)\n",
    "\n",
    "            # time transformation for query format\n",
    "            timeStart = times[0].strftime('%Y-%m-%dT%H:%M:%S')\n",
    "            timeEnd = times[-1].strftime('%Y-%m-%dT%H:%M:%S')\n",
    "            if times.tz._tzname == 'UTC':\n",
    "                timeStart +='Z'\n",
    "                timeEnd += 'Z'\n",
    "            else:\n",
    "                decstr = times[0].strftime('%z')\n",
    "                decstr = decstr[:-2] + ':' + decstr[-2:]\n",
    "                timeStart += decstr\n",
    "                timeEnd += decstr\n",
    "\n",
    "            interval = pandas.Timedelta(times.freq).seconds\n",
    "                \n",
    "            for station in stationId:\n",
    "                logging.info('start connecting to station %s' % station)\n",
    "                path=os.path.join(pathCache(),str(station)+'_'+str(parameters)+\"_\"+timeStart.split(\"T\")[0]+\"_\"+timeEnd.split(\"T\")[0]+'.json')\n",
    "                \n",
    "                \n",
    "                if usecache and os.path.exists(path):\n",
    "                    with open(path) as f:\n",
    "                        data=json.load(f)\n",
    "                else:        \n",
    "                    data = self.ipm.get_weatheradapter(\n",
    "                                    endpoint=self.endpoint,\n",
    "                                    weatherStationId=station,\n",
    "                                    timeStart=timeStart,\n",
    "                                    timeEnd=timeEnd,\n",
    "                                    interval=interval,\n",
    "                                    parameters=parameters,\n",
    "                                    credentials= credentials)\n",
    "                    \n",
    "                \n",
    "                if type(data) is dict:\n",
    "                    responses.append(data)\n",
    "                elif type(data) is int:\n",
    "                    logging.warning('HTTPError: %s for %s' %(data,station))   \n",
    "                \n",
    "                if savecache and type(data) is dict:\n",
    "                    with open(path,'w') as f:\n",
    "                        json.dump(data, f)  \n",
    "                \n",
    "        elif self.endpoint==\"https://ipmdecisions.nibio.no/api/wx/rest/weatheradapter/dmipoint\":\n",
    "            stationId=None\n",
    "            interval=86400\n",
    "            \n",
    "            times= pandas.date_range(timeStart,timeEnd,freq='D',tz=timeZone)\n",
    "\n",
    "            # time transformation for query format\n",
    "            timeStart = times[0].strftime('%Y-%m-%dT%H:%M:%S')\n",
    "            timeEnd = times[-1].strftime('%Y-%m-%dT%H:%M:%S')\n",
    "            if times.tz._tzname == 'UTC':\n",
    "                timeStart +='Z'\n",
    "                timeEnd += 'Z'\n",
    "            else:\n",
    "                decstr = times[0].strftime('%z')\n",
    "                decstr = decstr[:-2] + ':' + decstr[-2:]\n",
    "                timeStart += decstr\n",
    "                timeEnd += decstr\n",
    "                \n",
    "            for el in range(len(latitude)):\n",
    "                path=os.path.join(pathCache(),str(timeStart)+'_'+str(timeEnd)+'_'+str(parameters)+str(altitude[el])+'_'+str(latitude[el])+\"_\"+str(longitude[el])+'.json')\n",
    "            \n",
    "                if usecache and os.path.exists(path):\n",
    "                    with open(path) as f:\n",
    "                        data=json.load(f)\n",
    "                else:\n",
    "                    data= self.ipm.get_weatheradapter_forecast(\n",
    "                        endpoint=self.endpoint, \n",
    "                        altitude= altitude[el],\n",
    "                        latitude=latitude[el],\n",
    "                        longitude=longitude[el],\n",
    "                        timeStart=timeStart,\n",
    "                        timeEnd=timeEnd,\n",
    "                        interval=interval,\n",
    "                        parameters=parameters\n",
    "                        )\n",
    "\n",
    "                if type(data) is dict:\n",
    "                    responses.append(data)\n",
    "                elif type(data) is int:\n",
    "                    logging.warning(\"HTTPError:%s for %s\" %(data,[altitude[el],latitude[el],longitude[el]]))\n",
    "                \n",
    "                if savecache and type(data) is dict:\n",
    "                    with open(path,'w') as f:\n",
    "                        json.dump(data, f)\n",
    "        else:\n",
    "            stationId=None\n",
    "            timeStart==None\n",
    "            timeEnd==None\n",
    "            interval=None\n",
    "            for el in range(len(latitude)):\n",
    "                path=os.path.join(pathCache(),str(altitude[el])+'_'+str(latitude[el])+\"_\"+str(longitude[el])+'.json')\n",
    "            \n",
    "                if usecache and os.path.exists(path):\n",
    "                    with open(path) as f:\n",
    "                        data=json.load(f)\n",
    "                else:\n",
    "                    data= self.ipm.get_weatheradapter_forecast(\n",
    "                        endpoint=self.endpoint, \n",
    "                        altitude= altitude[el],\n",
    "                        latitude=latitude[el],\n",
    "                        longitude=longitude[el])\n",
    "\n",
    "                if type(data) is dict:\n",
    "                    responses.append(data)\n",
    "                elif type(data) is int:\n",
    "                    logging.warning(\"HTTPError:%s for %s\" %(data,[altitude[el],latitude[el],longitude[el]]))\n",
    "                \n",
    "                if savecache and type(data) is dict:\n",
    "                    with open(path,'w') as f:\n",
    "                        json.dump(data, f)\n",
    "        \n",
    "        if display==\"ds\":\n",
    "            return self.__convert_xarray_dataset__(responses,stationId,varname,display)\n",
    "        else:\n",
    "            return responses\n",
    "    \n",
    "    def __convert_xarray_dataset__(self, responses,stationId,varname,display):\n",
    "        \n",
    "        if display != \"ds\":\n",
    "            return responses\n",
    "        else:\n",
    "            # times = pandas.date_range(\n",
    "            #     start=responses[0]['timeStart'], \n",
    "            #     end=responses[0]['timeEnd'], \n",
    "            #     freq=\"H\",\n",
    "            #     name=\"time\")\n",
    "            \n",
    "            times=pandas.date_range(start=responses[0][\"timeStart\"],\n",
    "                                    end=responses[0][\"timeEnd\"],\n",
    "                                    freq=str(responses[0][\"interval\"])+\"S\",\n",
    "                                    name=\"time\")\n",
    "            \n",
    "            #times.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "            \n",
    "            datas= [np.array(response['locationWeatherData'][0]['data']).astype(\"float\") for response in responses]\n",
    "            \n",
    "            dats = [[data[:,i].reshape(data.shape[0],1) for i in range(data.shape[1])] for data in datas]\n",
    "            \n",
    "\n",
    "            # construction of dict for dataset variable\n",
    "            data_vars=[{str(response['weatherParameters'][i]):(['time','location'],dat[i]) for i in range(len(response['weatherParameters']))} for response in responses for dat in dats]\n",
    "\n",
    "            # construction dictionnaire coordonnée\n",
    "            if stationId:\n",
    "                coords=[{'time':times.values,\n",
    "                'location':([stationId[el]]),\n",
    "                'lat':(\"location\",[float(responses[el]['locationWeatherData'][0]['latitude'])]),\n",
    "                'lon':(\"location\",[float(responses[el]['locationWeatherData'][0]['longitude'])]),\n",
    "                #'alt':[float(responses[el]['locationWeatherData'][0]['altitude'])]\n",
    "                } \n",
    "                for el in range(len(responses))]\n",
    "                \n",
    "            else:\n",
    "                coords=[{'time':times.values,\n",
    "                        'location':([str([responses[el]['locationWeatherData'][0]['latitude'],responses[el]['locationWeatherData'][0]['longitude']])]),\n",
    "                        'lat':('location',[responses[el]['locationWeatherData'][0]['latitude']]),\n",
    "                        'lon':('location',[responses[el]['locationWeatherData'][0]['longitude']]),\n",
    "            #'alt':[float(responses[el]['locationWeatherData'][0]['altitude'])]\n",
    "            } for el in range(len(responses))]\n",
    "                \n",
    "                    \n",
    "            # list de ds\n",
    "            list_ds=[xr.Dataset(data_vars[el], coords=coords[el]) for el in range(len(responses))]\n",
    "            \n",
    "            #merge ds\n",
    "            ds=xr.merge(list_ds)\n",
    "            \n",
    "            #add coordinates attributes\n",
    "            if stationId:\n",
    "                ds.coords['time'].attrs[\"name\"]=\"time\"\n",
    "                #ds.coords['location'].attrs['name']= 'WeatherStationId'\n",
    "                ds.coords['lat'].attrs['name']='latitude'\n",
    "                ds.coords['lat'].attrs['unit']='degrees_north'\n",
    "                ds.coords['lon'].attrs['name']='longitude'\n",
    "                ds.coords['lon'].attrs['unit']='degrees_east'\n",
    "            else:\n",
    "                #ds.coords['location'].attrs['name']='[latitude,longitude]'\n",
    "                ds.coords['lat'].attrs['name']='latitude'\n",
    "                ds.coords['lat'].attrs['unit']='degrees_north'\n",
    "                ds.coords['lon'].attrs['name']='longitude'\n",
    "                ds.coords['lon'].attrs['unit']='degrees_east'\n",
    "            \n",
    "            # add data variable  attributes\n",
    "            param = self.ipm.get_parameter()\n",
    "            p={str(item['id']): item for item in param if item['id'] in responses[0]['weatherParameters']}\n",
    "                    \n",
    "                \n",
    "            for el in list(ds.data_vars):\n",
    "                try:\n",
    "                    ds.data_vars[el].attrs=p[str(el)]\n",
    "                except KeyError as e:\n",
    "                    logging.exception(\"The weatherParameter not implemented; key error: %s\".format(e))\n",
    "            \n",
    "            # Attribute of dataset\n",
    "            if stationId:\n",
    "                ds.attrs['weatherRessource']=self.name\n",
    "                ds.attrs['weatherStationId']=stationId\n",
    "                ds.attrs['timeStart']=str(ds.coords['time'].values[0])\n",
    "                ds.attrs['timeEnd']=str(ds.coords['time'].values[-1])\n",
    "                ds.attrs['parameters']=list(ds.data_vars)\n",
    "            else:\n",
    "                ds.attrs['weatherRessource']=self.name\n",
    "                ds.attrs['timeStart']=str(ds.coords['time'].values[0])\n",
    "                ds.attrs['timeEnd']=str(ds.coords['time'].values[-1])\n",
    "                ds.attrs['parameters']=list(ds.data_vars)\n",
    "            \n",
    "            if varname==\"name\":\n",
    "                ds= ds.rename_vars(name_dict={str(ds[el].attrs['id']):ds[el].attrs['name'] for el in list(ds.keys())}) \n",
    "                \n",
    "        return ds\n",
    "    \n",
    "        \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING [agroservices:IPM:116]: \u001b[0m \u001b[34mstatus is not ok with Internal Server Error\u001b[0m\n",
      "\u001b[33mWARNING [agroservices:IPM:116]: \u001b[0m \u001b[34mstatus is not ok with Internal Server Error\u001b[0m\n",
      "\u001b[33mWARNING [agroservices:IPM:116]: \u001b[0m \u001b[34mstatus is not ok with Internal Server Error\u001b[0m\n",
      "\u001b[33mWARNING [agroservices:IPM:116]: \u001b[0m \u001b[34mstatus is not ok with Internal Server Error\u001b[0m\n",
      "\u001b[33mWARNING [agroservices:IPM:116]: \u001b[0m \u001b[34mstatus is not ok with Internal Server Error\u001b[0m\n",
      "\u001b[33mWARNING [agroservices:IPM:116]: \u001b[0m \u001b[34mstatus is not ok with Internal Server Error\u001b[0m\n",
      "WARNING:status is not ok with Internal Server Error\n",
      "WARNING:HTTPError:500 for [0, 56.488, 9.583]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3884/4168204193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_resources\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdmi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ressource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"DMI Pointweather service\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdmi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m84600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1112\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimeStart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"2021-09-30\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimeEnd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"2021-10-19\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m56.488\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9.583\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maltitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3884/976807531.py\u001b[0m in \u001b[0;36mdata\u001b[1;34m(self, parameters, stationId, timeStart, timeEnd, timeZone, altitude, longitude, latitude, credentials, interval, display, varname, usecache, savecache)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"ds\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convert_xarray_dataset__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstationId\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvarname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3884/976807531.py\u001b[0m in \u001b[0;36m__convert_xarray_dataset__\u001b[1;34m(self, responses, stationId, varname, display)\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;31m#     name=\"time\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             times=pandas.date_range(start=responses[0][\"timeStart\"],\n\u001b[0m\u001b[0;32m    286\u001b[0m                                     \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"timeEnd\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m                                     \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"interval\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"S\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ws=WeatherDataHub()\n",
    "ws.list_resources\n",
    "dmi=ws.get_ressource(name=\"DMI Pointweather service\")\n",
    "rep=dmi.data(parameters=[2001,1112],timeStart=\"2021-09-30\",timeEnd=\"2021-10-19\",latitude=[56.488],longitude=[9.583],altitude=[0],display=\"ds\")\n",
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ws=WeatherDataHub()\n",
    "\n",
    "ws.list_resources\n",
    "fmi=ws.get_ressource(name='Finnish Meteorological Institute measured data')\n",
    "list_station=[int(id) for id in fmi.stations.id]\n",
    "list_station.remove(137188) # HTTPerror 500\n",
    "list_station.remove(101649) # diff of length data\n",
    "list_station.remove(855522) #HTTPerror 500\n",
    "list_station.remove(137189)\n",
    "list_station.remove(126737)\n",
    "ds=fmi.data(parameters=[1002,3002],stationId=[101533],display=\"ds\",varname=\"id\",usecache=True, savecache=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmi.parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot(ds,varname, location=None,resample=None,date=None):\n",
    "    \n",
    "    if resample:\n",
    "        data=ds[varname].resample(time=resample).mean()\n",
    "        \n",
    "    else:\n",
    "        data=ds[varname]\n",
    "        \n",
    "    if location is not None:  \n",
    "        data_loc= data.sel(location=location)\n",
    "        data_loc.plot.line(x=\"time\")\n",
    "        # fig = plt.figure()\n",
    "        # ax = fig.add_subplot() \n",
    "        # ax.plot(x=data_loc.time,y=data_loc)\n",
    "    else:\n",
    "        data.plot.line(x=\"time\")\n",
    "    \n",
    "    if date is not None:\n",
    "        data_time = data.sel(time=date)\n",
    "        plt.bar(x=data_time.location.astype(\"str\"), height=data_time.values)\n",
    "        \n",
    "    return data  \n",
    "        \n",
    "        \n",
    "    \n",
    "plot(ds=ds,varname=\"1002\",resample=\"D\",date=None,location=[101533, 101185])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def station_plot(ds,varname=None,time=None,resample=None):\n",
    "    ext_lat_min=int(ds.lat.values.min()-1)\n",
    "    ext_lat_max=int(ds.lat.values.max()+1)\n",
    "    ext_lon_min=int(ds.lon.values.min()-1)\n",
    "    ext_lon_max=int(ds.lon.values.max()+1)\n",
    "    if resample:\n",
    "        ds = ds.resample(time=resample).mean()\n",
    "    else:\n",
    "        ds = ds\n",
    "        \n",
    "    df=ds.to_dataframe()\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfea.LAKES, zorder=3)\n",
    "    ax.add_feature(cfea.OCEAN, zorder=1)\n",
    "    ax.add_feature(cfea.COASTLINE, zorder=2)\n",
    "    ax.add_feature(cfea.LAND, zorder=1)\n",
    "    ax.add_feature(cfea.BORDERS, zorder=4)\n",
    "    ax.set_extent([ext_lon_min,ext_lon_max,ext_lat_min,ext_lat_max])\n",
    "    gl=ax.gridlines(draw_labels=True, zorder = 5)\n",
    "    gl.right_labels = False\n",
    "    gl.top_labels = False\n",
    "    if (varname and time) is None:\n",
    "        ax.scatter(x=df[\"lon\"].values,y=df[\"lat\"].values,transform=ccrs.PlateCarree(),color='k',s=10)\n",
    "    else:\n",
    "        ds.isel(time=time).plot.scatter(x='lon',y='lat',hue=varname,\n",
    "                             ax=ax,cmap='inferno',vmin=-5,vmax=25,\n",
    "                             transform=ccrs.PlateCarree(),marker='s',s=50, add_guide=True ,zorder=6)\n",
    "    #ax.text(x=df[\"lon\"].values,y=df[\"lat\"].values,s=df.index.get_level_values(\"location\"),color=\"k\")\n",
    "    # ax.text(x=float(ds.isel(time=0).lon.values)-0.5,y=float(ds.isel(time=0).lat.values),s=float(ds['1002'].isel(time=0).values),color=\"red\")\n",
    "    # ax.text(x=float(ds.isel(time=0).lon.values)-0.5,y=float(ds.isel(time=0).lat.values)-0.2,s=float(ds['3002'].isel(time=0).values),color=\"blue\")\n",
    "\n",
    "station_plot(ds, varname='1002',time=24,resample=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot temperature at a given time step\n",
    "ext_lat_min=int(ds.lat.values.min()-20)\n",
    "ext_lat_max=int(ds.lat.values.max()+20)\n",
    "ext_lon_min=int(ds.lon.values.min()-20)\n",
    "ext_lon_max=int(ds.lon.values.max()+20)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cfea.LAKES, zorder=3)\n",
    "ax.add_feature(cfea.OCEAN, zorder=1)\n",
    "ax.add_feature(cfea.COASTLINE, zorder=2)\n",
    "ax.add_feature(cfea.LAND, zorder=1)\n",
    "ax.add_feature(cfea.BORDERS, zorder=4)\n",
    "#ax.set_extent([ext_lon_min,ext_lon_max,ext_lat_min,ext_lat_max])\n",
    "gl=ax.gridlines(draw_labels=True, zorder = 5)\n",
    "gl.right_labels = False\n",
    "gl.top_labels = False\n",
    "ds.isel(time=50).plot.scatter(x='lon',y='lat',hue='1002',\n",
    "                             ax=ax,cmap='inferno',vmin=-5,vmax=25,\n",
    "                             transform=ccrs.PlateCarree(),marker='s',s=50, add_guide=True ,zorder=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.interpolate import (interpolate_to_grid, remove_nan_observations,\n",
    "                               remove_repeat_coordinates)\n",
    "ds.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_map(ds, proj, title):\n",
    "    \"\"\"Make our basic default map for plotting\"\"\"\n",
    "    ext_lat_min=ds.lat.values.min()-1\n",
    "    ext_lat_max=ds.lat.values.max()+1\n",
    "    ext_lon_min=ds.lon.values.min()-1\n",
    "    ext_lon_max=ds.lon.values.max()+1\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    view = fig.add_axes([0, 0, 1, 1], projection=proj)\n",
    "    view.set_title(title)\n",
    "    view.set_extent([ext_lon_min,ext_lon_max,ext_lat_min,ext_lat_max])\n",
    "    view.add_feature(cfeature.STATES.with_scale('50m'))\n",
    "    view.add_feature(cfeature.OCEAN)\n",
    "    view.add_feature(cfeature.COASTLINE)\n",
    "    view.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    return fig, view\n",
    "\n",
    "def station_test_data(ds, variable_names, proj_from=None, proj_to=None):\n",
    "    \n",
    "    value = ds[variable_names].isel(time=0).values\n",
    "    lon = ds.lon.values\n",
    "    lat = ds.lat.values\n",
    "\n",
    "    if proj_from is not None and proj_to is not None:\n",
    "        proj_points = proj_to.transform_points(proj_from, lon, lat)\n",
    "        return proj_points[:, 0], proj_points[:, 1], value\n",
    "\n",
    "    return lon, lat, value\n",
    "\n",
    "\n",
    "from_proj = ccrs.PlateCarree(central_longitude=ds.lon.values.mean())\n",
    "to_proj = ccrs.PlateCarree(central_longitude=ds.lon.values.mean())\n",
    "levels = list(range(-20, 20, 1))\n",
    "cmap = plt.get_cmap('magma')\n",
    "norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "\n",
    "\n",
    "x, y, temp = station_test_data(ds,'1002', from_proj, to_proj)\n",
    "# x, y, temp = remove_nan_observations(x, y, temp)\n",
    "# x, y, temp = remove_repeat_coordinates(x, y, temp)\n",
    "x,y,temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, temp = remove_nan_observations(x, y, temp)\n",
    "#x, y, temp = remove_repeat_coordinates(x, y, temp)\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx, gy, img = interpolate_to_grid(x, y, temp, interp_type='cressman', minimum_neighbors=1,\n",
    "                                  hres=75000, search_radius=100000)\n",
    "img = np.ma.masked_where(np.isnan(img), img)\n",
    "fig, view = basic_map(ds,to_proj, 'Linear')\n",
    "mmb = view.pcolormesh(gx, gy, img, cmap=cmap, norm=norm)\n",
    "fig.colorbar(mmb, shrink=.4, pad=0, boundaries=levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norway=ws.get_ressource(name='Met Norway Locationforecast')\n",
    "norway.data(latitude=[67.2828, 61.27], longitude=[14.3711,25.52], altitude=[70,70],display='ds',varname='id')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02ca071b7e78c344288e1079c8d0ea68009fe5a98fcc0669e2a2bbe220df75ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ipm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
